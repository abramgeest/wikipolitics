{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import read_sql\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymysql as mdb\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def datetime2str(t):\n",
    "    return \"%4d%02d%02d%02d\"%(t.year,t.month,t.day,t.hour)\n",
    "    \n",
    "def gen_feat(into):\n",
    "    avg=np.average(into)\n",
    "    if avg==0: avg=1\n",
    "    maxv= np.max(into)\n",
    "    minv= np.min(into)\n",
    "    rmsv= np.std(into)\n",
    "    difxv=np.max(np.diff(into))\n",
    "    difnv=np.min(np.diff(into))\n",
    "    return([maxv,minv,rmsv,difxv,difnv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat=True\n",
    "dateinput=datetime.datetime(2015,9,5,16)\n",
    "searchtopic=32\n",
    "numk=6\n",
    "\n",
    "numtopics=84\n",
    "\n",
    "afile=\"/Users/abramvandergeest/mysql_insightwiki_auth.txt\"\n",
    "a=open(afile)\n",
    "passwd=a.readline().rstrip()\n",
    "a.close()\n",
    "host='localhost'; user='abram.ghost';db='wikidata'\n",
    "con = mdb.connect(host, user, passwd, db)\n",
    "\n",
    "with con:\n",
    "    curt= con.cursor()\n",
    "    #sql=\"SELECT COUNT(*) FROM `topics` \"\n",
    "    \n",
    "    sql=\"SELECT `Id`,`topic_label`,`topic_string` FROM `topics`;\"\n",
    "    curt.execute(sql)\n",
    "    topics=[[0,'nothing','Filler to match index']]\n",
    "    for topic in curt:\n",
    "        topics.append(topic)\n",
    "\n",
    "data={}\n",
    "\n",
    "df=range(numtopics+1)\n",
    "with con:\n",
    "    curt= con.cursor()\n",
    "    sql=\"SELECT `Id`,`topic_label`,`topic_string` FROM `topics`;\"\n",
    "    curt.execute(sql)\n",
    "    for row in curt:\n",
    "        cur = con.cursor()\n",
    "        sql='''SELECT `page_views`.`count` AS `vc`,`page_views`.`date` AS `vd` \n",
    "             FROM `topics` INNER JOIN `page_views` on `topics`.`ID` = `page_views`.`topic_id` \n",
    "             WHERE `topics`.`id`=%s'''\n",
    "        \n",
    "        data[row[1]]=read_sql(sql, con,params=[row[0]])\n",
    "        #print row[0]\n",
    "        df[row[0]]=data[row[1]]\n",
    "\n",
    "topicdata=df\n",
    "\n",
    "#setting dates to take slice of data with\n",
    "datefin=dateinput+datetime.timedelta(days=7)\n",
    "di=datetime2str(dateinput)\n",
    "dfin=datetime2str(datefin)\n",
    "topicdata=df\n",
    "\n",
    "#initializing array to hold the rows to cluster\n",
    "#the 0th position is fake so that my index matches the sql index\n",
    "clusinp=[]\n",
    "if feat==True:\n",
    "    clusinp.append(gen_feat([0,0,0,0,0]))\n",
    "else:\n",
    "    clusinp.append([0,0,0,0])\n",
    "\n",
    "#populating my array to go into my Kmean\n",
    "for index,topic in enumerate(topics):\n",
    "    #topic=list(topics[index])\n",
    "    if topic[0]!=0:\n",
    "        d=topicdata[topic[0]]\n",
    "        #print d[ (d['vd']>di) & (d['vd']<dfin )]['vd'].values\n",
    "        \n",
    "        if feat==True: #use the slope/variation features\n",
    "            p=gen_feat(d[ (d['vd']>di) & (d['vd']<dfin )]['vc'].values)\n",
    "        else:  # just use the direct view counts\n",
    "            p=d[ (d['vd']>di) & (d['vd']<dfin )]['vc'].values\n",
    "        #print len(p),type(p),p\n",
    "        clusinp.append(p)\n",
    "\n",
    "#cleaning up my array making it numpy to go into my kmean\n",
    "clusinp=np.array(clusinp)\n",
    "clusinp[0]=clusinp[5] #making sure my through away first row matches in size\n",
    "\n",
    "#print clusinp\n",
    "#for i,l in enumerate(clusinp):\n",
    "#    print i,len(l),type(l), l\n",
    "#print type(clusinp), len(clusinp[0]),len(clusinp[45])\n",
    "\n",
    "#use Kmeans to find clustering for numk clusters\n",
    "kmeans=KMeans(n_clusters=numk,n_init=30,max_iter=500,init='random')\n",
    "kmeans.fit(clusinp)\n",
    "labels=kmeans.labels_\n",
    "\n",
    "#\n",
    "topinclus=[[] for i in xrange(numk)]\n",
    "for index,cluster in enumerate(labels):\n",
    "    topinclus[cluster].append(topics[index][0])\n",
    "\n",
    "#topinclus\n",
    "for index,k in enumerate(topinclus):\n",
    "    for t in k:\n",
    "        if t==searchtopic:\n",
    "            gsearch=index\n",
    "\n",
    "#Making a list of the topics in this group     \n",
    "simtopic=[]\n",
    "for i in topinclus[gsearch]:\n",
    "    simtopic.append(topics[i])\n",
    "\n",
    "#getting the average view for the chosen topic for the day\n",
    "dinp=dateinput\n",
    "di=datetime2str(datetime.datetime(dinp.year,dinp.month,dinp.day,0))\n",
    "dfin=datetime2str(datetime.datetime(dinp.year,dinp.month,dinp.day,23))\n",
    "d=df[searchtopic]\n",
    "pc=int(np.round(np.average(d[ (d['vd']>=di) & (d['vd']<=dfin )]['vc'].values)))\n",
    "\n",
    "print simtopic ,pc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
