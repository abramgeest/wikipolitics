{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import string\n",
    "import pymysql as mdb\n",
    "maketables=False\n",
    "maketables=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topicsfile=\"/Users/abramvandergeest/Dropbox/insight_work/topic_list.txt\"\n",
    "f=open(topicsfile)\n",
    "topics=f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = mdb.connect('localhost', 'abram.ghost', '', 'wikidata')\n",
    "####I NEED TO SET THIS TO A NON-GITHUB AUTHENTICATION LOCATION AND CHANGE PASSWORD\n",
    "\n",
    "#I should also create the  database if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if maketables==True:\n",
    "    #Makes topics table\n",
    "    with con:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"DROP TABLE IF EXISTS `topics`;\")\n",
    "        str=\"CREATE TABLE `topics` (`Id` INT PRIMARY KEY AUTO_INCREMENT, `topic_label` VARCHAR(64), `topic_string` VARCHAR(64));\"\n",
    "        cur.execute(str)\n",
    "    \n",
    "    #Populate topics table\n",
    "    with con:\n",
    "        for topic in topics:\n",
    "            label=\"\".join(topic.lower().split())\n",
    "            string=topic.rstrip()\n",
    "            sql=\"INSERT INTO `topics` (`topic_label`,`topic_string`) VALUES (%s,%s);\"\n",
    "            cur.execute(sql,(label,string))\n",
    "        \n",
    "    #Makes page_views table\n",
    "    with con:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"DROP TABLE IF EXISTS `page_views`;\")\n",
    "        str=\"CREATE TABLE `page_views` (`Id` INT PRIMARY KEY AUTO_INCREMENT, `topic_id` INT, `count` INT, `date` VARCHAR(64));\"\n",
    "        cur.execute(str)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unzip(d,fo,fo2):\n",
    "    wikiurl=\"http://dumps.wikimedia.org/other/pagecounts-raw/%4d/%4d-%02d/\"%(d.year,d.year,d.month)\n",
    "    gzfile=\"pagecounts-%4d%02d%02d-%02d0000.gz\"%(d.year,d.month,d.day,d.hour)\n",
    "    print gzfile\n",
    "    fn=wikiurl+gzfile\n",
    "    urllib.urlretrieve(fn,fo)\n",
    "    !gunzip -c $fo>$fo2\n",
    "    return\n",
    "\n",
    "def csv_to_reduceddf(fo2):\n",
    "    allwiki=pd.read_csv(fo2,delim_whitespace=True)\n",
    "    allwiki.columns=['lang','article','views','size']\n",
    "    enwiki=allwiki[allwiki['lang']=='en']\n",
    "    enwiki=enwiki[enwiki['size']>=50000]\n",
    "    return(enwiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe with all english pages of a large size\n",
    "print \"starting\"\n",
    "year=2015\n",
    "month=3\n",
    "day=1\n",
    "hour=16\n",
    "fo=\"/Users/abramvandergeest/wikidata/temp.gz\"\n",
    "fo2=\"/Users/abramvandergeest/wikidata/temp.txt\"\n",
    "d=datetime.datetime(year,month,day,hour)\n",
    "dt=datetime.timedelta(days=+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering loop\n",
      "pagecounts-20150301-160000.gz\n",
      "it is unzipped\n",
      "english entries separated\n",
      "2015030116\n"
     ]
    }
   ],
   "source": [
    "print \"entering loop\"\n",
    "\n",
    "while d<datetime.datetime(2015,3,1,17):\n",
    "    get_unzip(d,fo,fo2)  #gets the gz file at wikipedia and unzips it\n",
    "    print \"it is unzipped\"\n",
    "        \n",
    "    #reading wikiviews into df and keeping the english entries and reasonably larger pages\n",
    "    #allwiki=pd.read_csv(fo2,delim_whitespace=True)\n",
    "    #allwiki.columns=['lang','article','views','size']\n",
    "    #enwiki=allwiki[allwiki['lang']=='en']\n",
    "    #enwiki=enwiki[enwiki['size']>=50000]\n",
    "    enwiki=csv_to_reduceddf(fo2) #takes the unzipped file and pairs it down and puts it into a df\n",
    "    print \"english entries separated\"\n",
    "    \n",
    "    print date\n",
    "    d+=dt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering loop\n",
      "pagecounts-20150301-160000.gz\n",
      "it is unzipped\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f8396bc8b002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#enwiki=allwiki[allwiki['lang']=='en']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#enwiki=enwiki[enwiki['size']>=50000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0menwiki\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_to_reduceddf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"english entries separated\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bbc2793121ea>\u001b[0m in \u001b[0;36mcsv_to_reduceddf\u001b[0;34m(fo2)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcsv_to_reduceddf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mallwiki\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mallwiki\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'views'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0menwiki\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallwiki\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mallwiki\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:7544)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:8137)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser._concatenate_chunks (pandas/parser.c:22311)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/numpy/core/numerictypes.pyc\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(array_types, scalar_types)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0m_register_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalar_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m     \"\"\"\n\u001b[1;32m    972\u001b[0m     \u001b[0mDetermine\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mfollowing\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mcoercion\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print \"here\"\n",
    "#searching each article for the various topics queried and put the results in views\n",
    "date='%4d%02d%02d%02d'%(d.year,d.month,d.day,d.hour)\n",
    "dic={}\n",
    "views=[]\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    sql=\"SELECT `Id`,`topic_label`,`topic_string` FROM `topics`;\"\n",
    "    cur.execute(sql)\n",
    "    for row in cur:\n",
    "        tops=row[2].rstrip().split()\n",
    "        twiki=enwiki[np.logical_and.reduce([enwiki['article'].str.contains(top,case=False) for top in tops ])==True]\n",
    "        t=row[2].rstrip()\n",
    "        dic[t]=twiki['views'].sum(axis=0)\n",
    "    #print row[0],dic[t],date\n",
    "    views.append([row[0],dic[t],date])\n",
    "print \"pageviews sorted\"\n",
    "        \n",
    "    #\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    for view in views:\n",
    "        sql=\"INSERT INTO `page_views` (`topic_id`,`count`,`date`) VALUES (%s,%s,%s);\"\n",
    "        cur.execute(sql,view)\n",
    "        \n",
    "print date\n",
    "d+=dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering loop\n",
      "pagecounts-20150301-160000.gz\n",
      "it is unzipped\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e9837b5bbd5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#reading wikiviews into df and keeping the english entries and reasonably larger pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mallwiki\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mallwiki\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'views'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0menwiki\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallwiki\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mallwiki\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:7544)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:8137)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser._concatenate_chunks (pandas/parser.c:22311)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/abramvandergeest/anaconda/lib/python2.7/site-packages/numpy/core/numerictypes.pyc\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(array_types, scalar_types)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0m_register_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalar_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m     \"\"\"\n\u001b[1;32m    972\u001b[0m     \u001b[0mDetermine\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mfollowing\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mcoercion\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print \"entering loop\"\n",
    "\n",
    "#while d<datetime.datetime(2015,3,1,17):\n",
    "if True:\n",
    "    #getting an unzipping gz'ed wikiviews file\n",
    "    #wikiurl=\"http://dumps.wikimedia.org/other/pagecounts-raw/%4d/%4d-%02d/\"%(d.year,d.year,d.month)\n",
    "    #gzfile=\"pagecounts-%4d%02d%02d-%02d0000.gz\"%(d.year,d.month,d.day,d.hour)\n",
    "    #print gzfile\n",
    "    #fn=wikiurl+gzfile\n",
    "    #urllib.urlretrieve(fn,fo)\n",
    "    #!gunzip -c $fo>$fo2\n",
    "    get_unzip(d,fo,fo2)\n",
    "    print \"it is unzipped\"\n",
    "    \n",
    "    #reading wikiviews into df and keeping the english entries and reasonably larger pages\n",
    "    allwiki=pd.read_csv(fo2,delim_whitespace=True)\n",
    "    allwiki.columns=['lang','article','views','size']\n",
    "    enwiki=allwiki[allwiki['lang']=='en']\n",
    "    enwiki=enwiki[enwiki['size']>=50000]\n",
    "    print \"english entries separated\"\n",
    "    \n",
    "    #searching each article for the various topics queried and put the results in views\n",
    "    date='%4d%02d%02d%02d'%(d.year,d.month,d.day,d.hour)\n",
    "    dic={}\n",
    "    views=[]\n",
    "    with con:\n",
    "        cur = con.cursor()\n",
    "        sql=\"SELECT `Id`,`topic_label`,`topic_string` FROM `topics`;\"\n",
    "        cur.execute(sql)\n",
    "        for row in cur:\n",
    "            tops=row[2].rstrip().split()\n",
    "            twiki=enwiki[np.logical_and.reduce([enwiki['article'].str.contains(top,case=False) for top in tops ])==True]\n",
    "            t=row[2].rstrip()\n",
    "            dic[t]=twiki['views'].sum(axis=0)\n",
    "        #print row[0],dic[t],date\n",
    "        views.append([row[0],dic[t],date])\n",
    "    print \"pageviews sorted\"\n",
    "        \n",
    "    #\n",
    "    with con:\n",
    "        cur = con.cursor()\n",
    "        for view in views:\n",
    "            sql=\"INSERT INTO `page_views` (`topic_id`,`count`,`date`) VALUES (%s,%s,%s);\"\n",
    "            cur.execute(sql,view)\n",
    "        \n",
    "    print date\n",
    "    d+=dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
